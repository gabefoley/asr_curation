{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94c773b",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import py3Dmol\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27081240",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "base_url = \"https://www.ebi.ac.uk/pdbe/\"\n",
    "\n",
    "api_base = base_url + \"api/\"\n",
    "\n",
    "summary_url = api_base + 'pdb/entry/summary/'\n",
    "secondary_structure_url = api_base + 'pdb/entry/secondary_structure/'\n",
    "ligand_url = api_base + '/pdb/entry/ligand_monomers/'\n",
    "\n",
    "\n",
    "def make_summary(data):\n",
    "    \"\"\"\n",
    "    This function creates a summary for a PDB entry\n",
    "    by getting data for an entry, and extracting\n",
    "    pieces of information\n",
    "    \n",
    "    :param data: Dict\n",
    "    :return: String\n",
    "    \"\"\"\n",
    "    \n",
    "    pdb_id = \"\"\n",
    "    # Certain calls could return multiple PDB entries,\n",
    "    # but the GET summary call we use in this exercise\n",
    "    # will always return only one PDB entry\n",
    "    for key in data.keys():\n",
    "        pdb_id = key\n",
    "\n",
    "    # The data is a list of dictionaries, and for the summary information,\n",
    "    # it is always the first element of the list\n",
    "    entry = data[pdb_id][0]\n",
    "    \n",
    "    # Getting the title of the entry\n",
    "    title = entry['title']\n",
    "    \n",
    "    # Getting the release date of the entry\n",
    "    release_date = entry['release_date']\n",
    "    # Formatting the entry to make it more user-friendly\n",
    "    formatted_release_date = \"%s/%s/%s\" % (\n",
    "        release_date[:4], \n",
    "        release_date[4:6], \n",
    "        release_date[6:])\n",
    "    \n",
    "    # Getting the experimental methods\n",
    "    # Note that there can be multiple methods, so this is a list that\n",
    "    # needs to be iterated\n",
    "    experimental_methods = \"\"\n",
    "    for experimental_method in entry[\"experimental_method\"]:\n",
    "        if experimental_methods:\n",
    "            experimental_methods += \" and \"\n",
    "        experimental_methods += experimental_method\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Getting the assemblies\n",
    "    assemblies = ''\n",
    "    for assembly in entry['assemblies']:\n",
    "        if assembly:\n",
    "            # Blank out the form if it is a monomer (because it must be homo form)\n",
    "            if assembly['name'] == 'monomer':\n",
    "                form = \"\"\n",
    "            else:\n",
    "                form = assembly['form']\n",
    "                \n",
    "            if assembly['preferred']:\n",
    "                \n",
    "                assemblies += f\"Preferred form with assembly ID {assembly['assembly_id']} is a {form}{assembly['name']}\\n\"\n",
    "            else:\n",
    "                assemblies += f\"Non-preferred form with assembly ID {assembly['assembly_id']} is a {assembly['form']}{assembly['name']}\\n\"\n",
    "\n",
    "    # Getting the author list\n",
    "    authors = \"\".join(entry['entry_authors'])\n",
    "    \n",
    "#         'assemblies': [{'assembly_id': '1', 'form': 'homo', 'preferred': True, 'name': 'monomer'}, {'assembly_id': '2', 'form': 'homo', 'preferred': False, 'name': 'dimer'}]}]}\n",
    "    \n",
    "    \n",
    "        \n",
    "     \n",
    "    # Creating the summary text using all the extracted \n",
    "    # information\n",
    "    summary = f'Entry is titled \"{title}\" and was released on {formatted_release_date} \\n\\nThis entry was determined using {experimental_methods} \\nThe authors are {authors} \\n\\nAssembly information -\\n{assemblies}'\n",
    "\n",
    "    return summary\n",
    "\n",
    "def make_request(url, mode, pdb_id):\n",
    "    \"\"\"\n",
    "    This function can make GET and POST requests to\n",
    "    the PDBe API\n",
    "    \n",
    "    :param url: String,\n",
    "    :param mode: String,\n",
    "    :param pdb_id: String\n",
    "    :return: JSON or None\n",
    "    \"\"\"\n",
    "    if mode == \"get\":\n",
    "        response = requests.get(url=url+pdb_id)\n",
    "    elif mode == \"post\":\n",
    "        response = requests.post(url, data=pdb_id)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"[No data retrieved - %s] %s\" % (response.status_code, response.text))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_secondary_structure_ranges(pdb_id=None, pdb_list=None):\n",
    "    \"\"\"\n",
    "    This function calls the PDBe API and retrieves the residue\n",
    "    ranges of secondary structural elements in a single PDB entry\n",
    "    or in a list of PDB entries\n",
    "    \n",
    "    :param pdb_id: String,\n",
    "    :param pdb_list: String\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # If neither a single PDB id, nor a list was provided,\n",
    "    # exit the function\n",
    "    if not pdb_id and not pdb_list:\n",
    "        print(\"Either provide one PDB id, or a list of ids\")\n",
    "        return None\n",
    "    \n",
    "    if pdb_id:\n",
    "        # If a single PDB id was provided, call the API with GET\n",
    "        data = make_request(secondary_structure_url, \"get\", pdb_id)\n",
    "    else:\n",
    "        # If multiple PDB ids were provided, call the API with POST\n",
    "        # The POST API call expects PDB ids as a comma-separated lise\n",
    "        pdb_list_string = \", \".join(pdb_list)\n",
    "        data = make_request(secondary_structure_url, \"post\", pdb_list_string)\n",
    "        \n",
    "    # When no data is returned by the API, exit the function\n",
    "    if not data:\n",
    "        print(\"No data available\")\n",
    "        return None\n",
    "    \n",
    "    # Loop through all the PDB entries in the retrieved data\n",
    "    for entry_id in data.keys():\n",
    "        entry = data[entry_id]\n",
    "        molecules = entry[\"molecules\"]\n",
    "        \n",
    "        # Loop through all the molecules of a given PDB entry\n",
    "        for i in range(len(molecules)):\n",
    "            chains = molecules[i][\"chains\"]\n",
    "            \n",
    "            # Loop through all the chains of a given molecules\n",
    "            for j in range(len(chains)):\n",
    "                secondary_structure = chains[j][\"secondary_structure\"]\n",
    "                helices = secondary_structure[\"helices\"]\n",
    "                strands = secondary_structure[\"strands\"]\n",
    "                helix_list = []\n",
    "                strand_list = []\n",
    "                \n",
    "                # Loop through all the helices of a given chain\n",
    "                for k in range(len(helices)):\n",
    "                    start = helices[k][\"start\"][\"residue_number\"]\n",
    "                    end = helices[k][\"end\"][\"residue_number\"]\n",
    "                    helix_list.append(\"%s-%s\" % (start, end))\n",
    "                \n",
    "                # Loop through all the strands of a given chain\n",
    "                for l in range(len(strands)):\n",
    "                    start = strands[l][\"start\"][\"residue_number\"]\n",
    "                    end = strands[l][\"end\"][\"residue_number\"]\n",
    "                    strand_list.append(\"%s-%s\" % (start, end))\n",
    "                    \n",
    "                report = \"%s chain %s has \" % (entry_id, chains[j][\"chain_id\"])\n",
    "                if len(helix_list) > 0:\n",
    "                    report += \"helices at residue ranges %s \" % str(helix_list)\n",
    "                else:\n",
    "                    report += \"no helices \"\n",
    "                report += \"and \"\n",
    "                if len(strand_list) > 0:\n",
    "                    report += \"strands at %s\" % str(strand_list)\n",
    "                else:\n",
    "                    \"no strands\"\n",
    "                print(report)\n",
    "                \n",
    "    return None\n",
    "\n",
    "def get_ligand_information(data):\n",
    "    pdb_id = \"\"\n",
    "    \n",
    "    summary = \"\"\n",
    "\n",
    "    for key in data.keys():\n",
    "        pdb_id = key\n",
    "        \n",
    "    for ligand in data[pdb_id]:\n",
    "        summary += f\"Ligand : {ligand['chem_comp_name']} at position {ligand['author_residue_number']}\\n\"\n",
    "        \n",
    "    return summary\n",
    "    \n",
    "\n",
    "def get_entry_from_api(pdb_id, api_url):\n",
    "    \"\"\"\n",
    "    This function will make a call to the PDBe API using\n",
    "    the PDB id and API url provided as arguments\n",
    "    \n",
    "    :param pdb_id: String,\n",
    "    :param api_url: String\n",
    "    :return: Dict or None\n",
    "    \"\"\"\n",
    "    if not re.match(\"[0-9][A-Za-z][A-Za-z0-9]{2}\", pdb_id):\n",
    "        print(\"Invalid PDB id\")\n",
    "        return None\n",
    "    \n",
    "    # Make a GET call to the API URL\n",
    "    get_request = requests.get(url=api_url+pdb_id)\n",
    "    \n",
    "    if get_request.status_code == 200:\n",
    "        # If there is data returned (with HTML status code 200)\n",
    "        # then return the data in JSON format\n",
    "        return get_request.json()\n",
    "    else:\n",
    "        # If there is no data, print status code and response\n",
    "        print(get_request.status_code, get_request.text)\n",
    "        return None\n",
    "\n",
    "\n",
    "# As you can hopefully see, the data displayed is very similar to\n",
    "# what we had in the mock data in previous sections - however,\n",
    "# this is actual data coming from the PDBe API\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac8f1b",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "print(display(Markdown(f'# Summary - {snakemake.wildcards.dataset}')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa47c9",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "print (f'Summary sheet - {snakemake.wildcards.dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd27e4f7",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(snakemake.input[0])\n",
    "non_fragment_df = df[df['Fragment'] == False]\n",
    "entry_df = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36671ba2",
   "metadata": {},
   "source": [
    "# EC numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a7aa0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "ec_nums = list(pd.unique(df['EC_number']))\n",
    "\n",
    "ec_set = set()\n",
    "\n",
    "for num in ec_nums:\n",
    "    for split in str(num).split(\";\"):\n",
    "        ec_set.add(split.strip())\n",
    "    \n",
    "print (f'The EC numbers found in the current data set are {ec_set}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7807b",
   "metadata": {},
   "source": [
    "# Taxonomic distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a50473a",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "taxonomy_cols = ['Taxonomic_lineage_SUPERKINGDOM', 'Taxonomic_lineage_PHYLUM']\n",
    "\n",
    "for col in taxonomy_cols:\n",
    "    fig, ax = plt.subplots(figsize=(len(col) / 3 ,10))\n",
    "    chart = df[col].value_counts().plot.barh(title=col, ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb988d9",
   "metadata": {},
   "source": [
    "# Annotation distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f577e66",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "key_annotation_cols = snakemake.params.annotation_cols\n",
    "for col in key_annotation_cols:\n",
    "    if col in entry_df:\n",
    "        fig, ax = plt.subplots(figsize=(len(col) / 3 ,10))\n",
    "        chart = entry_df[col].value_counts().plot.barh(title=col, ax=ax)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa21732",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "seq_len = df['Length'].describe()\n",
    "non_fragment_seq_len = non_fragment_df['Length'].describe()\n",
    "\n",
    "\n",
    "def print_sequence_summarys(seq_summary):\n",
    "    print (f\"Number of sequences : {seq_summary['count']}\")\n",
    "    print (f\"Smallest sequnce length : {seq_summary['min']}\")\n",
    "    print (f\"Longest sequnce length : {seq_summary['max']}\")\n",
    "    print (f\"Average sequnce length : {seq_summary['mean']}\")\n",
    "\n",
    "print (\"Sequence statistics for all sequences\")\n",
    "print_sequence_summarys(seq_len)\n",
    "\n",
    "print ()\n",
    "\n",
    "if non_fragment_seq_len.all():\n",
    "\n",
    "    print (\"Sequence statistics for sequences (non-fragments)\")\n",
    "    print_sequence_summarys(non_fragment_seq_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f901775",
   "metadata": {},
   "source": [
    "# Experimental data (BRENDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a67c7",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "skip_brenda_cols = [\n",
    "'BRENDA_CL', 'BRENDA_GI', \n",
    "'BRENDA_SN', 'BRENDA_SY', \n",
    "'BRENDA_MW', 'BRENDA_SP',\n",
    "'BRENDA_NSP', 'BRENDA_PM',\n",
    "'BRENDA_LO', 'BRENDA_SU', \n",
    "'BRENDA_PU', 'BRENDA_ST',\n",
    "'BRENDA_CR', 'BRENDA_CF',\n",
    "'BRENDA_RN', 'BRENDA_RT',\n",
    "'BRENDA_ME', 'BRENDA_REFERENCES']\n",
    "\n",
    "\n",
    "# Only get the columns that start with BRENDA and that we don't want to skip\n",
    "brenda_cols =[x for x in df if x.startswith(\"BRENDA\") and 'COMMENT' not in x and 'REFS' not in x and 'UNITS' not in x and not any(skip in x for skip in skip_brenda_cols)]\n",
    "\n",
    "# Drop rows if they don't have at least one entry in one of the BRENDA columns\n",
    "b_df = df[brenda_cols].dropna(thresh=1)\n",
    "print (len(brenda_cols))\n",
    "fig, ax = plt.subplots(figsize=(len(brenda_cols) / 4 ,10))\n",
    "\n",
    "\n",
    "# Create and save a plot of the BRENDA column counts\n",
    "if len(b_df) > 0:\n",
    "    b_df.count().plot.barh(ax=ax)\n",
    "    display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd19acf",
   "metadata": {},
   "source": [
    "# Structural information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7b8d3",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "pdb_df = df[['Entry', 'Cross_reference_PDB']].dropna()\n",
    "pdb_dict = defaultdict(list)\n",
    "for pdb_entries in pdb_df.itertuples():\n",
    "    pdb_dict[pdb_entries.Entry] = [x for x in pdb_entries.Cross_reference_PDB.strip().split(\";\") if len(x) > 0]\n",
    "\n",
    "total_structures = sum([len(x) for x in pdb_dict.values()])\n",
    "\n",
    "print (f\"There are {total_structures} total structures across {len(pdb_dict.keys())} unique sequences\")\n",
    "\n",
    "print (\"Looking at the first few...\")\n",
    "\n",
    "sample_pdb_dict = {k: pdb_dict[k] for k in list(pdb_dict)[:3]}\n",
    "\n",
    "for prot_id, pdb_ids in sample_pdb_dict.items():\n",
    "    for pdb_id in pdb_ids:\n",
    "        \n",
    "        display(Markdown(f'# {pdb_id} PDB entry information'))\n",
    "\n",
    "        print(make_summary(get_entry_from_api(pdb_id, summary_url)))\n",
    "        \n",
    "        display(Markdown(f'# {pdb_id} Ligand informtion'))    \n",
    "        print(get_ligand_information(get_entry_from_api(pdb_id, ligand_url)))\n",
    "        \n",
    "    \n",
    "        display(Markdown(f'# {pdb_id} Secondary structure ranges'))\n",
    "        get_secondary_structure_ranges(pdb_id)\n",
    "        \n",
    "        display(Markdown(f'# {pdb_id}'))\n",
    "        \n",
    "        view = py3Dmol.view(query=f'pdb:{pdb_id}')\n",
    "        view.setStyle({'cartoon':{'color':'spectrum'}})\n",
    "        display(view)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8694229f",
   "metadata": {},
   "source": [
    "# General data set information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f18dc",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "display(Markdown(f\"These are the columns that are available and have at least one entry\"))\n",
    "\n",
    "for x in entry_df.keys():\n",
    "    if not x.startswith(\"BRENDA\"):\n",
    "        print (x)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
