Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                               count    min threads    max threads
------------------------------  -------  -------------  -------------
add_annotations_from_alignment        3              1              1
add_annotations_from_ancestors        3              1              1
add_custom_annotations                2              1              1
align_seqs                            3              1              1
all                                   1              1              1
clean_subset_summary                  3              1              1
clean_summary_document                2              1              1
compile_summary_document              3              1              1
create_annotation_file                3              1              1
create_annotations                    1              1              1
create_dataset_summary                2              1              1
create_subset_document                3              1              1
create_subset_summary                 3              1              1
create_subsets                        3              1              1
get_brenda_annotations                2              1              1
get_uniprot_annotations               1              1              1
infer_tree                            3              1              1
run_grasp                             3              1              1
total                                44              1              1

Select jobs to execute...

[Mon May 30 16:47:09 2022]
rule get_brenda_annotations:
    input: workflows/example_workflow/datasets/uniprot_ec_1_1_1_86_filtered_reviewed_yes/csv/uniprot/uniprot_ec_1_1_1_86_filtered_reviewed_yes_uniprot.csv
    output: workflows/example_workflow/datasets/uniprot_ec_1_1_1_86_filtered_reviewed_yes/csv/brenda/uniprot_ec_1_1_1_86_filtered_reviewed_yes_brenda.csv
    jobid: 6
    reason: Missing output files: workflows/example_workflow/datasets/uniprot_ec_1_1_1_86_filtered_reviewed_yes/csv/brenda/uniprot_ec_1_1_1_86_filtered_reviewed_yes_brenda.csv
    wildcards: dataset=uniprot_ec_1_1_1_86_filtered_reviewed_yes
    resources: tmpdir=/var/folders/xs/24s9hwqd191f2x7rhdy6_ryc0000gr/T

[Mon May 30 16:48:01 2022]
Error in rule get_brenda_annotations:
    jobid: 6
    output: workflows/example_workflow/datasets/uniprot_ec_1_1_1_86_filtered_reviewed_yes/csv/brenda/uniprot_ec_1_1_1_86_filtered_reviewed_yes_brenda.csv

RuleException:
CalledProcessError in line 224 of /Users/uqgfoley/Documents/asr_curation_moved/asr_curation/Snakefile:
Command 'set -euo pipefail;  /Users/uqgfoley/opt/miniconda3/envs/asr_curation240/bin/python /Users/uqgfoley/Documents/asr_curation_moved/asr_curation/.snakemake/scripts/tmptpjnqb0o.get_brenda_annotations.py' returned non-zero exit status 1.
  File "/Users/uqgfoley/Documents/asr_curation_moved/asr_curation/Snakefile", line 224, in __rule_get_brenda_annotations
  File "/Users/uqgfoley/opt/miniconda3/envs/asr_curation240/lib/python3.8/concurrent/futures/thread.py", line 57, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2022-05-30T164708.531258.snakemake.log
